{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7vCViUxhKbqKFvogqTZhj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adhiksha007/AI-Bootcamp/blob/main/Basic_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JOa5tp-yQm2H"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "XnO6X2bGQtZa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmiod_derivative(x):\n",
        "  return x * (1 - x)"
      ],
      "metadata": {
        "id": "YXobdzR2Q2mt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "  return np.mean(np.square(y_true - y_pred))"
      ],
      "metadata": {
        "id": "FR4cWwz7Q-fv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "    self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "    self.bias_hidden = np.random.randn(1, hidden_size)\n",
        "    self.bias_output = np.random.randn(1, output_size)\n",
        "\n",
        "    # Forward pass\n",
        "  def forward(self, X):\n",
        "    self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden\n",
        "    self.hidden_output = sigmoid(self.hidden_input)\n",
        "    self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output\n",
        "    self.output = sigmoid(self.output_input)\n",
        "    return self.output\n",
        "\n",
        "    # backward pass and weights update\n",
        "  def backward(self, X, y, output, learning_rate):\n",
        "    output_error = y - output\n",
        "    output_delta = output_error * sigmiod_derivative(output)\n",
        "\n",
        "    hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "    hidden_delta = hidden_error * sigmiod_derivative(self.hidden_output)\n",
        "\n",
        "    self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate\n",
        "    self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "    self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate\n",
        "    self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Training the neural network\n",
        "  def train(self, X, y, epochs, learning_rate):\n",
        "    for epoch in range(epochs):\n",
        "      output = self.forward(X)\n",
        "      self.backward(X, y, output, learning_rate)\n",
        "      if epoch % 100 == 0:\n",
        "        loss = mean_squared_error(y, output)\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')"
      ],
      "metadata": {
        "id": "K6QH0KOyRMJn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])"
      ],
      "metadata": {
        "id": "NV1jjrwnTx6G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork(2, 2, 1)\n",
        "nn.train(X, y, epochs=10000, learning_rate=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-O2QKXHUHFC",
        "outputId": "81602011-e8b7-46a1-f97b-78033ea4004e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.25859740330043834\n",
            "Epoch 100, Loss: 0.25221433031424034\n",
            "Epoch 200, Loss: 0.2510254789674483\n",
            "Epoch 300, Loss: 0.24948849024495562\n",
            "Epoch 400, Loss: 0.24741835664940254\n",
            "Epoch 500, Loss: 0.2446842659434159\n",
            "Epoch 600, Loss: 0.24124669915312033\n",
            "Epoch 700, Loss: 0.23716556178193043\n",
            "Epoch 800, Loss: 0.232557876154948\n",
            "Epoch 900, Loss: 0.227545917316043\n",
            "Epoch 1000, Loss: 0.22224847693409128\n",
            "Epoch 1100, Loss: 0.21680200561313745\n",
            "Epoch 1200, Loss: 0.2113681991805788\n",
            "Epoch 1300, Loss: 0.20611173361165325\n",
            "Epoch 1400, Loss: 0.20116466040004594\n",
            "Epoch 1500, Loss: 0.19660181769776824\n",
            "Epoch 1600, Loss: 0.19243742599281657\n",
            "Epoch 1700, Loss: 0.18863692044778538\n",
            "Epoch 1800, Loss: 0.18513290303234084\n",
            "Epoch 1900, Loss: 0.18183756433943377\n",
            "Epoch 2000, Loss: 0.178648904319996\n",
            "Epoch 2100, Loss: 0.1754510060945268\n",
            "Epoch 2200, Loss: 0.17210953094291742\n",
            "Epoch 2300, Loss: 0.1684637175722884\n",
            "Epoch 2400, Loss: 0.1643166754285596\n",
            "Epoch 2500, Loss: 0.15942786505069434\n",
            "Epoch 2600, Loss: 0.1535166092923404\n",
            "Epoch 2700, Loss: 0.14629248464186756\n",
            "Epoch 2800, Loss: 0.13752899952049782\n",
            "Epoch 2900, Loss: 0.12717543853054902\n",
            "Epoch 3000, Loss: 0.11546021076164528\n",
            "Epoch 3100, Loss: 0.10291414396090623\n",
            "Epoch 3200, Loss: 0.09026686974171422\n",
            "Epoch 3300, Loss: 0.07824560491896752\n",
            "Epoch 3400, Loss: 0.06738504822428294\n",
            "Epoch 3500, Loss: 0.057947841157493664\n",
            "Epoch 3600, Loss: 0.04996085991556255\n",
            "Epoch 3700, Loss: 0.04330407219651786\n",
            "Epoch 3800, Loss: 0.037793517576397005\n",
            "Epoch 3900, Loss: 0.033235439187943756\n",
            "Epoch 4000, Loss: 0.029453417985231913\n",
            "Epoch 4100, Loss: 0.026298047719598483\n",
            "Epoch 4200, Loss: 0.023647558418552296\n",
            "Epoch 4300, Loss: 0.021404650217424347\n",
            "Epoch 4400, Loss: 0.019492270437801187\n",
            "Epoch 4500, Loss: 0.017849548437926264\n",
            "Epoch 4600, Loss: 0.016428321622566185\n",
            "Epoch 4700, Loss: 0.015190329490147968\n",
            "Epoch 4800, Loss: 0.014105011728691958\n",
            "Epoch 4900, Loss: 0.01314780519841818\n",
            "Epoch 5000, Loss: 0.012298835035346706\n",
            "Epoch 5100, Loss: 0.01154191003189053\n",
            "Epoch 5200, Loss: 0.01086375024878335\n",
            "Epoch 5300, Loss: 0.01025339102737906\n",
            "Epoch 5400, Loss: 0.009701720904636398\n",
            "Epoch 5500, Loss: 0.009201121366718943\n",
            "Epoch 5600, Loss: 0.008745184331531285\n",
            "Epoch 5700, Loss: 0.008328489231974056\n",
            "Epoch 5800, Loss: 0.00794642603988656\n",
            "Epoch 5900, Loss: 0.007595053900912701\n",
            "Epoch 6000, Loss: 0.007270987534014069\n",
            "Epoch 6100, Loss: 0.006971305405746923\n",
            "Epoch 6200, Loss: 0.006693475082004575\n",
            "Epoch 6300, Loss: 0.0064352922091201695\n",
            "Epoch 6400, Loss: 0.006194830370537032\n",
            "Epoch 6500, Loss: 0.005970399669702815\n",
            "Epoch 6600, Loss: 0.005760512352265091\n",
            "Epoch 6700, Loss: 0.0055638541363211376\n",
            "Epoch 6800, Loss: 0.005379260194527709\n",
            "Epoch 6900, Loss: 0.0052056949457208596\n",
            "Epoch 7000, Loss: 0.005042234980834638\n",
            "Epoch 7100, Loss: 0.004888054579216137\n",
            "Epoch 7200, Loss: 0.004742413375120243\n",
            "Epoch 7300, Loss: 0.0046046458164422\n",
            "Epoch 7400, Loss: 0.004474152123348479\n",
            "Epoch 7500, Loss: 0.004350390507015925\n",
            "Epoch 7600, Loss: 0.004232870450975651\n",
            "Epoch 7700, Loss: 0.0041211468917336375\n",
            "Epoch 7800, Loss: 0.004014815163079543\n",
            "Epoch 7900, Loss: 0.003913506591100558\n",
            "Epoch 8000, Loss: 0.003816884645415425\n",
            "Epoch 8100, Loss: 0.0037246415673364876\n",
            "Epoch 8200, Loss: 0.003636495408193583\n",
            "Epoch 8300, Loss: 0.0035521874214181513\n",
            "Epoch 8400, Loss: 0.003471479760590731\n",
            "Epoch 8500, Loss: 0.0033941534428251234\n",
            "Epoch 8600, Loss: 0.003320006542854083\n",
            "Epoch 8700, Loss: 0.0032488525882067047\n",
            "Epoch 8800, Loss: 0.0031805191300929366\n",
            "Epoch 8900, Loss: 0.0031148464681760024\n",
            "Epoch 9000, Loss: 0.0030516865104292063\n",
            "Epoch 9100, Loss: 0.002990901751831816\n",
            "Epoch 9200, Loss: 0.0029323643578355765\n",
            "Epoch 9300, Loss: 0.0028759553403894\n",
            "Epoch 9400, Loss: 0.00282156381589683\n",
            "Epoch 9500, Loss: 0.002769086335841517\n",
            "Epoch 9600, Loss: 0.0027184262819851058\n",
            "Epoch 9700, Loss: 0.0026694933190482156\n",
            "Epoch 9800, Loss: 0.0026222028986546825\n",
            "Epoch 9900, Loss: 0.0025764758090709274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X)):\n",
        "  print(f\"Input: {X[i]}, Predicted Output: {nn.forward(X[i])}, Actual output: {y[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJS4ixf6UaBW",
        "outputId": "35f5a76b-d654-4260-d2b3-19799be67c2c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [0 0], Predicted Output: [[0.0436162]], Actual output: [0]\n",
            "Input: [0 1], Predicted Output: [[0.94766026]], Actual output: [1]\n",
            "Input: [1 0], Predicted Output: [[0.94763597]], Actual output: [1]\n",
            "Input: [1 1], Predicted Output: [[0.05239407]], Actual output: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P23BRymZWSeq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}