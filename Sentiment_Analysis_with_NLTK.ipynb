{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiI1sz7R0kGT3n6qvcLsNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adhiksha007/AI-Bootcamp/blob/main/Sentiment_Analysis_with_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e7StTFNCI9aG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"movie_reviews\")\n",
        "nltk.download(\"punkt\")  # used to split sentences into words\n",
        "nltk.download(\"stopwords\")  # used to remove common words like \"the\", \"a\", etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AiDlI57KN2P",
        "outputId": "dea5874e-7ef6-47ea-b4ec-7168ee612c2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the dataset and extract the features\n",
        "def extract_features(words):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    features = {}\n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            features[word] = True\n",
        "    return features"
      ],
      "metadata": {
        "id": "L59ZhfMfFUQ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the dataset\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)\n",
        "             ]\n",
        "\n",
        "# Randomize the documents\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "vIMmWqXjF1uL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset for training and testing\n",
        "featuresets = [(extract_features(d), c) for (d, c) in documents]\n",
        "train_set, test_set = featuresets[1600:], featuresets[:1600]"
      ],
      "metadata": {
        "id": "87IW51QZGWVI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed the naive bayers classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "6jNdCDZUHVTp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the classifier on the test dataset\n",
        "accuracy = accuracy(classifier, test_set)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWh7d2RjHtMg",
        "outputId": "4e237739-9806-4071-b236-d320ff12fa25"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the most informative features\n",
        "classifier.show_most_informative_features(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qwrq3aWH2qQ",
        "outputId": "73b83efb-7909-492c-cf4e-106fec8b8611"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             outstanding = True              pos : neg    =     11.5 : 1.0\n",
            "                 subplot = True              neg : pos    =     11.5 : 1.0\n",
            "                   awful = True              neg : pos    =     10.2 : 1.0\n",
            "                  wasted = True              neg : pos    =      9.9 : 1.0\n",
            "               initially = True              pos : neg    =      8.7 : 1.0\n",
            "                     era = True              pos : neg    =      7.6 : 1.0\n",
            "                   badly = True              neg : pos    =      7.5 : 1.0\n",
            "                 crystal = True              neg : pos    =      7.5 : 1.0\n",
            "              uninspired = True              neg : pos    =      7.5 : 1.0\n",
            "                 unfunny = True              neg : pos    =      7.3 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model on new input data\n",
        "def analyze_sentiment(text):\n",
        "    features = extract_features(nltk.word_tokenize(text))\n",
        "    return classifier.classify(features)"
      ],
      "metadata": {
        "id": "QwFjPfk5IG-S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-M3HfvQJIRU",
        "outputId": "60f7c173-a30c-4801-946b-232ed97dad9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the classifier\n",
        "print(analyze_sentiment(\"This movie was fantastic!\"))\n",
        "print(analyze_sentiment(\"This movie was terrible!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zi5n_pFIvI8",
        "outputId": "4931f7fc-4adb-4168-882a-daf2f286f2d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos\n",
            "neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j97dN9TrI2Nm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}